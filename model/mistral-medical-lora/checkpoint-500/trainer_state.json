{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.4566731362027629,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009133462724055257,
      "grad_norm": 0.3013763427734375,
      "learning_rate": 0.0001,
      "loss": 1.4276,
      "step": 10
    },
    {
      "epoch": 0.018266925448110514,
      "grad_norm": 0.3728012144565582,
      "learning_rate": 0.0002,
      "loss": 1.2323,
      "step": 20
    },
    {
      "epoch": 0.027400388172165772,
      "grad_norm": 0.31142672896385193,
      "learning_rate": 0.00019907749077490775,
      "loss": 1.0811,
      "step": 30
    },
    {
      "epoch": 0.03653385089622103,
      "grad_norm": 0.25764018297195435,
      "learning_rate": 0.00019815498154981552,
      "loss": 1.075,
      "step": 40
    },
    {
      "epoch": 0.04566731362027629,
      "grad_norm": 0.27453529834747314,
      "learning_rate": 0.00019723247232472326,
      "loss": 1.0152,
      "step": 50
    },
    {
      "epoch": 0.054800776344331545,
      "grad_norm": 0.2233482152223587,
      "learning_rate": 0.000196309963099631,
      "loss": 0.9377,
      "step": 60
    },
    {
      "epoch": 0.0639342390683868,
      "grad_norm": 0.24355782568454742,
      "learning_rate": 0.00019538745387453877,
      "loss": 0.9379,
      "step": 70
    },
    {
      "epoch": 0.07306770179244206,
      "grad_norm": 0.22107098996639252,
      "learning_rate": 0.00019446494464944652,
      "loss": 0.9423,
      "step": 80
    },
    {
      "epoch": 0.08220116451649731,
      "grad_norm": 0.2265830636024475,
      "learning_rate": 0.00019354243542435426,
      "loss": 0.998,
      "step": 90
    },
    {
      "epoch": 0.09133462724055258,
      "grad_norm": 0.24885812401771545,
      "learning_rate": 0.000192619926199262,
      "loss": 0.9318,
      "step": 100
    },
    {
      "epoch": 0.10046808996460783,
      "grad_norm": 0.20606379210948944,
      "learning_rate": 0.00019169741697416974,
      "loss": 0.9388,
      "step": 110
    },
    {
      "epoch": 0.10960155268866309,
      "grad_norm": 0.2483375072479248,
      "learning_rate": 0.00019077490774907748,
      "loss": 0.9205,
      "step": 120
    },
    {
      "epoch": 0.11873501541271834,
      "grad_norm": 0.2221204787492752,
      "learning_rate": 0.00018985239852398525,
      "loss": 0.9507,
      "step": 130
    },
    {
      "epoch": 0.1278684781367736,
      "grad_norm": 0.21750620007514954,
      "learning_rate": 0.000188929889298893,
      "loss": 0.8758,
      "step": 140
    },
    {
      "epoch": 0.13700194086082887,
      "grad_norm": 0.22370903193950653,
      "learning_rate": 0.00018800738007380074,
      "loss": 0.8797,
      "step": 150
    },
    {
      "epoch": 0.1461354035848841,
      "grad_norm": 0.20983123779296875,
      "learning_rate": 0.0001870848708487085,
      "loss": 0.9322,
      "step": 160
    },
    {
      "epoch": 0.15526886630893938,
      "grad_norm": 0.19913350045681,
      "learning_rate": 0.00018616236162361625,
      "loss": 0.9371,
      "step": 170
    },
    {
      "epoch": 0.16440232903299462,
      "grad_norm": 0.21175818145275116,
      "learning_rate": 0.000185239852398524,
      "loss": 0.9291,
      "step": 180
    },
    {
      "epoch": 0.1735357917570499,
      "grad_norm": 0.21299564838409424,
      "learning_rate": 0.00018431734317343173,
      "loss": 0.9119,
      "step": 190
    },
    {
      "epoch": 0.18266925448110516,
      "grad_norm": 0.19879214465618134,
      "learning_rate": 0.0001833948339483395,
      "loss": 0.9336,
      "step": 200
    },
    {
      "epoch": 0.1918027172051604,
      "grad_norm": 0.21600374579429626,
      "learning_rate": 0.00018247232472324724,
      "loss": 0.9199,
      "step": 210
    },
    {
      "epoch": 0.20093617992921567,
      "grad_norm": 0.21935969591140747,
      "learning_rate": 0.00018154981549815499,
      "loss": 0.9271,
      "step": 220
    },
    {
      "epoch": 0.2100696426532709,
      "grad_norm": 0.19997148215770721,
      "learning_rate": 0.00018062730627306276,
      "loss": 0.9228,
      "step": 230
    },
    {
      "epoch": 0.21920310537732618,
      "grad_norm": 0.22181983292102814,
      "learning_rate": 0.0001797047970479705,
      "loss": 0.9191,
      "step": 240
    },
    {
      "epoch": 0.22833656810138145,
      "grad_norm": 0.22972598671913147,
      "learning_rate": 0.00017878228782287824,
      "loss": 0.8509,
      "step": 250
    },
    {
      "epoch": 0.2374700308254367,
      "grad_norm": 0.20209188759326935,
      "learning_rate": 0.00017785977859778598,
      "loss": 0.8808,
      "step": 260
    },
    {
      "epoch": 0.24660349354949196,
      "grad_norm": 0.21355898678302765,
      "learning_rate": 0.00017693726937269372,
      "loss": 0.909,
      "step": 270
    },
    {
      "epoch": 0.2557369562735472,
      "grad_norm": 0.21358487010002136,
      "learning_rate": 0.00017601476014760147,
      "loss": 0.8782,
      "step": 280
    },
    {
      "epoch": 0.26487041899760244,
      "grad_norm": 0.20727936923503876,
      "learning_rate": 0.00017509225092250923,
      "loss": 0.9037,
      "step": 290
    },
    {
      "epoch": 0.27400388172165774,
      "grad_norm": 0.22119593620300293,
      "learning_rate": 0.00017416974169741698,
      "loss": 0.904,
      "step": 300
    },
    {
      "epoch": 0.283137344445713,
      "grad_norm": 0.22062358260154724,
      "learning_rate": 0.00017324723247232472,
      "loss": 0.8482,
      "step": 310
    },
    {
      "epoch": 0.2922708071697682,
      "grad_norm": 0.22013501822948456,
      "learning_rate": 0.0001723247232472325,
      "loss": 0.8602,
      "step": 320
    },
    {
      "epoch": 0.3014042698938235,
      "grad_norm": 0.2301793247461319,
      "learning_rate": 0.00017140221402214023,
      "loss": 0.9698,
      "step": 330
    },
    {
      "epoch": 0.31053773261787876,
      "grad_norm": 0.1990135908126831,
      "learning_rate": 0.00017047970479704797,
      "loss": 0.9473,
      "step": 340
    },
    {
      "epoch": 0.319671195341934,
      "grad_norm": 0.20537593960762024,
      "learning_rate": 0.00016955719557195574,
      "loss": 0.9455,
      "step": 350
    },
    {
      "epoch": 0.32880465806598924,
      "grad_norm": 0.20992253720760345,
      "learning_rate": 0.00016863468634686348,
      "loss": 0.8558,
      "step": 360
    },
    {
      "epoch": 0.33793812079004454,
      "grad_norm": 0.19600069522857666,
      "learning_rate": 0.00016771217712177123,
      "loss": 0.8776,
      "step": 370
    },
    {
      "epoch": 0.3470715835140998,
      "grad_norm": 0.21098431944847107,
      "learning_rate": 0.00016678966789667897,
      "loss": 0.8744,
      "step": 380
    },
    {
      "epoch": 0.356205046238155,
      "grad_norm": 0.26497796177864075,
      "learning_rate": 0.00016586715867158674,
      "loss": 0.8863,
      "step": 390
    },
    {
      "epoch": 0.3653385089622103,
      "grad_norm": 0.21664339303970337,
      "learning_rate": 0.00016494464944649448,
      "loss": 0.8327,
      "step": 400
    },
    {
      "epoch": 0.37447197168626556,
      "grad_norm": 0.19974668323993683,
      "learning_rate": 0.00016402214022140222,
      "loss": 0.8649,
      "step": 410
    },
    {
      "epoch": 0.3836054344103208,
      "grad_norm": 0.20814305543899536,
      "learning_rate": 0.00016309963099630996,
      "loss": 0.8838,
      "step": 420
    },
    {
      "epoch": 0.3927388971343761,
      "grad_norm": 0.2275354266166687,
      "learning_rate": 0.0001621771217712177,
      "loss": 0.8381,
      "step": 430
    },
    {
      "epoch": 0.40187235985843134,
      "grad_norm": 0.19296669960021973,
      "learning_rate": 0.00016125461254612547,
      "loss": 0.8242,
      "step": 440
    },
    {
      "epoch": 0.4110058225824866,
      "grad_norm": 0.1949186623096466,
      "learning_rate": 0.00016033210332103322,
      "loss": 0.8811,
      "step": 450
    },
    {
      "epoch": 0.4201392853065418,
      "grad_norm": 0.22817623615264893,
      "learning_rate": 0.00015940959409594096,
      "loss": 0.8644,
      "step": 460
    },
    {
      "epoch": 0.4292727480305971,
      "grad_norm": 0.19387534260749817,
      "learning_rate": 0.0001584870848708487,
      "loss": 0.8967,
      "step": 470
    },
    {
      "epoch": 0.43840621075465236,
      "grad_norm": 0.22086107730865479,
      "learning_rate": 0.00015756457564575647,
      "loss": 0.8183,
      "step": 480
    },
    {
      "epoch": 0.4475396734787076,
      "grad_norm": 0.22450858354568481,
      "learning_rate": 0.0001566420664206642,
      "loss": 0.9094,
      "step": 490
    },
    {
      "epoch": 0.4566731362027629,
      "grad_norm": 0.2014199048280716,
      "learning_rate": 0.00015571955719557195,
      "loss": 0.866,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2188,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "total_flos": 1.1683962218510746e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
